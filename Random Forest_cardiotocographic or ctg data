
# Read Data
data <- read.csv("C:/Users/uidj1620/Desktop/Desktop/Folder/B RAI/Random Forest/Patient data_Normal, patho, suspect/CTG.csv", header = TRUE)
str(data)
data$NSP <- as.factor(data$NSP)
table(data$NSP)
### NSP- normal, suspect, pathologic


# Data Partition
set.seed(1234)
## ind = independent samples
ind <- sample(2, nrow(data), replace = TRUE, prob = c(0.7, 0.3))
train <- data[ind==1,]
test <- data[ind==2,]

# Random Forest
library(randomForest)
set.seed(1234)
rf <- randomForest(NSP~., data=train,
                   ntree = 300,
                   mtry = 8,
                   importance = TRUE,
                   proximity = TRUE)
print(rf)
attributes(rf)
## OOB - out of bag error is 5.57 means accuracy is 96%.



### if we want to see values of any of the attributes use:
rf$confusion

# Prediction & Confusion Matrix - train data
install.packages("e1071")
library(caret)
library(e1071)
p1 <- predict(rf, train)
confusionMatrix(p1, train$NSP)

# # Prediction & Confusion Matrix - test data
p2 <- predict(rf, test)
confusionMatrix(p2, test$NSP)

# Error rate of Random Forest
plot(rf)

# Tune the random forest model , tune mtry(finding which mtry to choose) , 22nd variable is NSP
t <- tuneRF(train[,-22], train[,22],
            stepFactor = 0.5,
            plot = TRUE,
            ntreeTry = 300,
            trace = TRUE,
            improve = 0.05)
## improve refers to relative improvement in OOB by this much for the search to continue
### step factor is mtry is inflated or deflated at each iteration by this value


# No. of nodes for the trees
## size of trees depanding on the number of nodes 
## below code is for number of nodes in each of the 300 trees 
hist(treesize(rf),
     main = "No. of Nodes for the Trees",
     col = "green")

# Variable Importance( importance of each variable in accuracy of the model)
## Gini captures how pure the nodes are at the end of the tree

varImpPlot(rf,
           sort = T,
           n.var = 10,
           main = "Top 10 - Variable Importance")
## n.var parameter represents how many variables we need to show
## Numerical values of important variables
importance(rf)

## below code is to find which variables were used to predict the model
## numbers represents the number of times each variable occured in the model
varUsed(rf)

# Partial Dependence Plot
partialPlot(rf, train, ASTV, "2")

# Extract Single Tree(extract information about a single tree, in this case tree 1)
## status = -1 means a terminal node
getTree(rf, 1, labelVar = TRUE)

# Multi-dimensional Scaling Plot of Proximity Matrix
MDSplot(rf, train$NSP)
